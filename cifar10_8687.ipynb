{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyroGRRfVdYrFWZKJfizc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igrodfer/DeepLearningLab/blob/main/cifar10_8687.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h5wdHR13H09N"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Add\n",
        "from keras.layers import BatchNormalization as BN\n",
        "from keras.layers import GaussianNoise as GN\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from keras import Input, Model\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "GpI8v1zTuKyl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBkZNs-FuNRX",
        "outputId": "a27fe465-91fa-449d-9a42-deedf235fd1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n")"
      ],
      "metadata": {
        "id": "DDLd-1f1uTVl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resblock(x, filters,ds=False):\n",
        "  fx = Conv2D(filters, (3,3), strides=(1 if not ds else 2), padding='same')(x)\n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  fx = Activation('relu')(fx)\n",
        "\n",
        "  fx = Conv2D(filters, (3,3), padding='same')(fx)\n",
        "\n",
        "  if ds:\n",
        "    x = Conv2D(filters, (1,1),strides=2, padding='same')(x)\n",
        "\n",
        "  out = Add()([x,fx])\n",
        "\n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  out = Activation('relu')(fx)\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "48aEBFEPIHkI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CBGN(x,filters,ishape=0):\n",
        "  if (ishape!=0):\n",
        "    fx = Conv2D(filters, (3, 3), padding='same',\n",
        "                 input_shape=ishape)(x)\n",
        "  else:\n",
        "    fx = Conv2D(filters, (3, 3), padding='same')(x)\n",
        "  \n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  fx = Activation('relu')(fx)\n",
        "  fx = MaxPooling2D(pool_size=(2, 2))(fx)\n",
        "  \n",
        "  return fx"
      ],
      "metadata": {
        "id": "Fqwy-6K1Jbkq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=x_train.shape[1:])\n",
        "\n",
        "out = CBGN(input,32)\n",
        "out = resblock(out,32)\n",
        "out = resblock(out,32)\n",
        "\n",
        "out = resblock(out,64,True)\n",
        "out = resblock(out,64)\n",
        "out = resblock(out,64)\n",
        "\n",
        "out = resblock(out,128,True)\n",
        "out = resblock(out,128)\n",
        "out = resblock(out,128)\n",
        "\n",
        "out = resblock(out,256,True)\n",
        "out = resblock(out,256)\n",
        "out = resblock(out,256)\n",
        "\n",
        "out = resblock(out,512,True)\n",
        "out = resblock(out,512)\n",
        "\n",
        "out = Flatten()(out)\n",
        "out = Dense(512)(out)\n",
        "out = BN()(out)\n",
        "out = GN(0.3)(out)\n",
        "out = Activation('relu')(out)\n",
        "\n",
        "out = Flatten()(out)\n",
        "out = Dense(num_classes)(out)\n",
        "out = Activation('softmax')(out)\n",
        "\n",
        "model = Model(input,out)"
      ],
      "metadata": {
        "id": "5IbFeCXrKoeY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-xJ3cOuFvCMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## OPTIM AND COMPILE\n",
        "opt = SGD(learning_rate=0.01, decay=1e-6,momentum=0.9)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "g4ZCddjbvMZ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(x_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            verbose=1)\n",
        "\n",
        "## TEST\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ99AM-1vOdz",
        "outputId": "5c0055bc-0c76-4024-9032-3ce42ba9c6bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "500/500 [==============================] - 47s 69ms/step - loss: 2.2884 - accuracy: 0.1351 - val_loss: 2.4240 - val_accuracy: 0.1402\n",
            "Epoch 2/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 2.0384 - accuracy: 0.2026 - val_loss: 2.5534 - val_accuracy: 0.2112\n",
            "Epoch 3/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 1.9682 - accuracy: 0.2336 - val_loss: 2.3478 - val_accuracy: 0.2301\n",
            "Epoch 4/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.9262 - accuracy: 0.2607 - val_loss: 2.2167 - val_accuracy: 0.1752\n",
            "Epoch 5/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.9224 - accuracy: 0.2640 - val_loss: 1.8944 - val_accuracy: 0.2767\n",
            "Epoch 6/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.8800 - accuracy: 0.2801 - val_loss: 1.9648 - val_accuracy: 0.2629\n",
            "Epoch 7/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 1.8450 - accuracy: 0.2971 - val_loss: 1.9841 - val_accuracy: 0.2623\n",
            "Epoch 8/200\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 1.8013 - accuracy: 0.3166 - val_loss: 1.6911 - val_accuracy: 0.3619\n",
            "Epoch 9/200\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 1.6723 - accuracy: 0.3625 - val_loss: 1.8300 - val_accuracy: 0.3775\n",
            "Epoch 10/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.6114 - accuracy: 0.3946 - val_loss: 1.6316 - val_accuracy: 0.4458\n",
            "Epoch 11/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.5448 - accuracy: 0.4259 - val_loss: 2.6567 - val_accuracy: 0.3313\n",
            "Epoch 12/200\n",
            "500/500 [==============================] - 37s 75ms/step - loss: 1.4876 - accuracy: 0.4538 - val_loss: 1.7625 - val_accuracy: 0.4292\n",
            "Epoch 13/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 1.4421 - accuracy: 0.4750 - val_loss: 1.6899 - val_accuracy: 0.4690\n",
            "Epoch 14/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.3905 - accuracy: 0.4992 - val_loss: 1.5442 - val_accuracy: 0.5098\n",
            "Epoch 15/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.3594 - accuracy: 0.5109 - val_loss: 2.1181 - val_accuracy: 0.4488\n",
            "Epoch 16/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.3280 - accuracy: 0.5237 - val_loss: 1.8268 - val_accuracy: 0.4960\n",
            "Epoch 17/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.2857 - accuracy: 0.5430 - val_loss: 1.5797 - val_accuracy: 0.5099\n",
            "Epoch 18/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.2551 - accuracy: 0.5525 - val_loss: 1.4524 - val_accuracy: 0.5478\n",
            "Epoch 19/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 1.2253 - accuracy: 0.5694 - val_loss: 1.2488 - val_accuracy: 0.5986\n",
            "Epoch 20/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 1.1876 - accuracy: 0.5861 - val_loss: 1.1707 - val_accuracy: 0.6182\n",
            "Epoch 21/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.1503 - accuracy: 0.6036 - val_loss: 1.4518 - val_accuracy: 0.5611\n",
            "Epoch 22/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.1161 - accuracy: 0.6154 - val_loss: 1.1640 - val_accuracy: 0.6329\n",
            "Epoch 23/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.0716 - accuracy: 0.6290 - val_loss: 2.0476 - val_accuracy: 0.4942\n",
            "Epoch 24/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.0576 - accuracy: 0.6313 - val_loss: 1.1853 - val_accuracy: 0.6078\n",
            "Epoch 25/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 1.0140 - accuracy: 0.6502 - val_loss: 1.1624 - val_accuracy: 0.6200\n",
            "Epoch 26/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.9954 - accuracy: 0.6559 - val_loss: 1.1280 - val_accuracy: 0.6490\n",
            "Epoch 27/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.9781 - accuracy: 0.6628 - val_loss: 1.0895 - val_accuracy: 0.6497\n",
            "Epoch 28/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.9477 - accuracy: 0.6761 - val_loss: 1.1168 - val_accuracy: 0.6483\n",
            "Epoch 29/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.9328 - accuracy: 0.6817 - val_loss: 1.0323 - val_accuracy: 0.6741\n",
            "Epoch 30/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.9129 - accuracy: 0.6905 - val_loss: 0.9104 - val_accuracy: 0.7072\n",
            "Epoch 31/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.8913 - accuracy: 0.7018 - val_loss: 0.9211 - val_accuracy: 0.7118\n",
            "Epoch 32/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.8831 - accuracy: 0.7034 - val_loss: 1.1970 - val_accuracy: 0.6445\n",
            "Epoch 33/200\n",
            "500/500 [==============================] - 38s 75ms/step - loss: 0.8629 - accuracy: 0.7094 - val_loss: 1.0939 - val_accuracy: 0.6508\n",
            "Epoch 34/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.8448 - accuracy: 0.7164 - val_loss: 0.9098 - val_accuracy: 0.7137\n",
            "Epoch 35/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.8279 - accuracy: 0.7244 - val_loss: 0.8542 - val_accuracy: 0.7274\n",
            "Epoch 36/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.8132 - accuracy: 0.7300 - val_loss: 0.8329 - val_accuracy: 0.7322\n",
            "Epoch 37/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.8045 - accuracy: 0.7339 - val_loss: 0.8151 - val_accuracy: 0.7339\n",
            "Epoch 38/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.7897 - accuracy: 0.7374 - val_loss: 0.7727 - val_accuracy: 0.7575\n",
            "Epoch 39/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.7737 - accuracy: 0.7445 - val_loss: 0.8178 - val_accuracy: 0.7432\n",
            "Epoch 40/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.7723 - accuracy: 0.7456 - val_loss: 0.9610 - val_accuracy: 0.7098\n",
            "Epoch 41/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.7545 - accuracy: 0.7516 - val_loss: 0.8350 - val_accuracy: 0.7439\n",
            "Epoch 42/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.7444 - accuracy: 0.7552 - val_loss: 0.8655 - val_accuracy: 0.7290\n",
            "Epoch 43/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.7322 - accuracy: 0.7577 - val_loss: 0.8669 - val_accuracy: 0.7310\n",
            "Epoch 44/200\n",
            "500/500 [==============================] - 37s 75ms/step - loss: 0.7245 - accuracy: 0.7598 - val_loss: 0.7196 - val_accuracy: 0.7748\n",
            "Epoch 45/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.7133 - accuracy: 0.7651 - val_loss: 0.7921 - val_accuracy: 0.7537\n",
            "Epoch 46/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.7062 - accuracy: 0.7688 - val_loss: 1.0490 - val_accuracy: 0.6863\n",
            "Epoch 47/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6919 - accuracy: 0.7737 - val_loss: 0.6734 - val_accuracy: 0.7831\n",
            "Epoch 48/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6886 - accuracy: 0.7739 - val_loss: 0.7421 - val_accuracy: 0.7644\n",
            "Epoch 49/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6879 - accuracy: 0.7762 - val_loss: 0.7572 - val_accuracy: 0.7537\n",
            "Epoch 50/200\n",
            "500/500 [==============================] - 38s 75ms/step - loss: 0.6721 - accuracy: 0.7805 - val_loss: 0.6802 - val_accuracy: 0.7787\n",
            "Epoch 51/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.6727 - accuracy: 0.7814 - val_loss: 0.7024 - val_accuracy: 0.7790\n",
            "Epoch 52/200\n",
            "500/500 [==============================] - 41s 81ms/step - loss: 0.6576 - accuracy: 0.7850 - val_loss: 0.7041 - val_accuracy: 0.7820\n",
            "Epoch 53/200\n",
            "500/500 [==============================] - 39s 78ms/step - loss: 0.6402 - accuracy: 0.7895 - val_loss: 0.6964 - val_accuracy: 0.7825\n",
            "Epoch 54/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.6422 - accuracy: 0.7913 - val_loss: 0.8680 - val_accuracy: 0.7459\n",
            "Epoch 55/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.6366 - accuracy: 0.7930 - val_loss: 0.8084 - val_accuracy: 0.7515\n",
            "Epoch 56/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.6355 - accuracy: 0.7939 - val_loss: 0.7732 - val_accuracy: 0.7562\n",
            "Epoch 57/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6277 - accuracy: 0.7963 - val_loss: 0.6912 - val_accuracy: 0.7786\n",
            "Epoch 58/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6198 - accuracy: 0.7966 - val_loss: 0.8333 - val_accuracy: 0.7466\n",
            "Epoch 59/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6090 - accuracy: 0.8019 - val_loss: 0.7220 - val_accuracy: 0.7738\n",
            "Epoch 60/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.6048 - accuracy: 0.8043 - val_loss: 0.6805 - val_accuracy: 0.7845\n",
            "Epoch 61/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.5977 - accuracy: 0.8046 - val_loss: 0.6670 - val_accuracy: 0.7839\n",
            "Epoch 62/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.5907 - accuracy: 0.8082 - val_loss: 0.7052 - val_accuracy: 0.7720\n",
            "Epoch 63/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.5824 - accuracy: 0.8097 - val_loss: 0.6672 - val_accuracy: 0.7874\n",
            "Epoch 64/200\n",
            "500/500 [==============================] - 39s 78ms/step - loss: 0.5804 - accuracy: 0.8105 - val_loss: 0.6677 - val_accuracy: 0.7901\n",
            "Epoch 65/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.5793 - accuracy: 0.8123 - val_loss: 0.6313 - val_accuracy: 0.7974\n",
            "Epoch 66/200\n",
            "500/500 [==============================] - 39s 77ms/step - loss: 0.5643 - accuracy: 0.8156 - val_loss: 0.6148 - val_accuracy: 0.8043\n",
            "Epoch 67/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5649 - accuracy: 0.8154 - val_loss: 0.8239 - val_accuracy: 0.7471\n",
            "Epoch 68/200\n",
            "500/500 [==============================] - 38s 77ms/step - loss: 0.5600 - accuracy: 0.8174 - val_loss: 0.5758 - val_accuracy: 0.8172\n",
            "Epoch 69/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5493 - accuracy: 0.8211 - val_loss: 0.6925 - val_accuracy: 0.7872\n",
            "Epoch 70/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5483 - accuracy: 0.8217 - val_loss: 0.6018 - val_accuracy: 0.8072\n",
            "Epoch 71/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.5382 - accuracy: 0.8223 - val_loss: 0.6152 - val_accuracy: 0.8058\n",
            "Epoch 72/200\n",
            "500/500 [==============================] - 39s 77ms/step - loss: 0.5360 - accuracy: 0.8240 - val_loss: 0.6002 - val_accuracy: 0.8048\n",
            "Epoch 73/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5328 - accuracy: 0.8252 - val_loss: 0.5523 - val_accuracy: 0.8232\n",
            "Epoch 74/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.5307 - accuracy: 0.8279 - val_loss: 0.6735 - val_accuracy: 0.7923\n",
            "Epoch 75/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5234 - accuracy: 0.8296 - val_loss: 0.5461 - val_accuracy: 0.8268\n",
            "Epoch 76/200\n",
            "500/500 [==============================] - 38s 75ms/step - loss: 0.5159 - accuracy: 0.8329 - val_loss: 0.8156 - val_accuracy: 0.7625\n",
            "Epoch 77/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5157 - accuracy: 0.8325 - val_loss: 0.7086 - val_accuracy: 0.7846\n",
            "Epoch 78/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5040 - accuracy: 0.8333 - val_loss: 0.8600 - val_accuracy: 0.7364\n",
            "Epoch 79/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.5063 - accuracy: 0.8341 - val_loss: 0.6565 - val_accuracy: 0.7954\n",
            "Epoch 80/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4994 - accuracy: 0.8370 - val_loss: 0.6415 - val_accuracy: 0.8015\n",
            "Epoch 81/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4930 - accuracy: 0.8381 - val_loss: 0.5889 - val_accuracy: 0.8173\n",
            "Epoch 82/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4959 - accuracy: 0.8370 - val_loss: 0.5540 - val_accuracy: 0.8238\n",
            "Epoch 83/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4891 - accuracy: 0.8405 - val_loss: 0.5369 - val_accuracy: 0.8272\n",
            "Epoch 84/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4832 - accuracy: 0.8423 - val_loss: 0.5961 - val_accuracy: 0.8157\n",
            "Epoch 85/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4829 - accuracy: 0.8422 - val_loss: 0.5786 - val_accuracy: 0.8111\n",
            "Epoch 86/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4765 - accuracy: 0.8437 - val_loss: 0.5304 - val_accuracy: 0.8299\n",
            "Epoch 87/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4696 - accuracy: 0.8462 - val_loss: 0.5342 - val_accuracy: 0.8295\n",
            "Epoch 88/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4715 - accuracy: 0.8460 - val_loss: 0.5423 - val_accuracy: 0.8259\n",
            "Epoch 89/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.4690 - accuracy: 0.8471 - val_loss: 0.7080 - val_accuracy: 0.7840\n",
            "Epoch 90/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4655 - accuracy: 0.8473 - val_loss: 0.5202 - val_accuracy: 0.8387\n",
            "Epoch 91/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4628 - accuracy: 0.8490 - val_loss: 0.5619 - val_accuracy: 0.8173\n",
            "Epoch 92/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4552 - accuracy: 0.8488 - val_loss: 0.6236 - val_accuracy: 0.8036\n",
            "Epoch 93/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4522 - accuracy: 0.8509 - val_loss: 0.5195 - val_accuracy: 0.8377\n",
            "Epoch 94/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.4476 - accuracy: 0.8518 - val_loss: 0.6963 - val_accuracy: 0.7879\n",
            "Epoch 95/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.4455 - accuracy: 0.8527 - val_loss: 0.4805 - val_accuracy: 0.8448\n",
            "Epoch 96/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4459 - accuracy: 0.8523 - val_loss: 0.5473 - val_accuracy: 0.8269\n",
            "Epoch 97/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4367 - accuracy: 0.8551 - val_loss: 0.5202 - val_accuracy: 0.8357\n",
            "Epoch 98/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4396 - accuracy: 0.8565 - val_loss: 0.5239 - val_accuracy: 0.8360\n",
            "Epoch 99/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4391 - accuracy: 0.8560 - val_loss: 0.4623 - val_accuracy: 0.8524\n",
            "Epoch 100/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4371 - accuracy: 0.8565 - val_loss: 0.4904 - val_accuracy: 0.8455\n",
            "Epoch 101/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4253 - accuracy: 0.8597 - val_loss: 0.5124 - val_accuracy: 0.8426\n",
            "Epoch 102/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.4301 - accuracy: 0.8589 - val_loss: 0.5081 - val_accuracy: 0.8405\n",
            "Epoch 103/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4256 - accuracy: 0.8618 - val_loss: 0.5144 - val_accuracy: 0.8411\n",
            "Epoch 104/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4256 - accuracy: 0.8601 - val_loss: 0.4836 - val_accuracy: 0.8441\n",
            "Epoch 105/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.4220 - accuracy: 0.8613 - val_loss: 0.5540 - val_accuracy: 0.8277\n",
            "Epoch 106/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4250 - accuracy: 0.8603 - val_loss: 0.4669 - val_accuracy: 0.8484\n",
            "Epoch 107/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4138 - accuracy: 0.8633 - val_loss: 0.5084 - val_accuracy: 0.8343\n",
            "Epoch 108/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4152 - accuracy: 0.8629 - val_loss: 0.4603 - val_accuracy: 0.8521\n",
            "Epoch 109/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4129 - accuracy: 0.8652 - val_loss: 0.5745 - val_accuracy: 0.8197\n",
            "Epoch 110/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4096 - accuracy: 0.8655 - val_loss: 0.4860 - val_accuracy: 0.8455\n",
            "Epoch 111/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4119 - accuracy: 0.8640 - val_loss: 0.5315 - val_accuracy: 0.8315\n",
            "Epoch 112/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4014 - accuracy: 0.8673 - val_loss: 0.5790 - val_accuracy: 0.8220\n",
            "Epoch 113/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4046 - accuracy: 0.8671 - val_loss: 0.5098 - val_accuracy: 0.8393\n",
            "Epoch 114/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4032 - accuracy: 0.8680 - val_loss: 0.5094 - val_accuracy: 0.8395\n",
            "Epoch 115/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4004 - accuracy: 0.8696 - val_loss: 0.4603 - val_accuracy: 0.8533\n",
            "Epoch 116/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3975 - accuracy: 0.8685 - val_loss: 0.5648 - val_accuracy: 0.8254\n",
            "Epoch 117/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3981 - accuracy: 0.8684 - val_loss: 0.4967 - val_accuracy: 0.8396\n",
            "Epoch 118/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3932 - accuracy: 0.8705 - val_loss: 0.5229 - val_accuracy: 0.8321\n",
            "Epoch 119/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3919 - accuracy: 0.8712 - val_loss: 0.4519 - val_accuracy: 0.8607\n",
            "Epoch 120/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3872 - accuracy: 0.8727 - val_loss: 0.4771 - val_accuracy: 0.8456\n",
            "Epoch 121/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3863 - accuracy: 0.8712 - val_loss: 0.4840 - val_accuracy: 0.8425\n",
            "Epoch 122/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.3816 - accuracy: 0.8734 - val_loss: 0.4987 - val_accuracy: 0.8446\n",
            "Epoch 123/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3774 - accuracy: 0.8763 - val_loss: 0.5016 - val_accuracy: 0.8480\n",
            "Epoch 124/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3808 - accuracy: 0.8746 - val_loss: 0.5464 - val_accuracy: 0.8303\n",
            "Epoch 125/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3777 - accuracy: 0.8757 - val_loss: 0.6779 - val_accuracy: 0.7978\n",
            "Epoch 126/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3750 - accuracy: 0.8756 - val_loss: 0.5257 - val_accuracy: 0.8395\n",
            "Epoch 127/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3774 - accuracy: 0.8755 - val_loss: 0.4766 - val_accuracy: 0.8529\n",
            "Epoch 128/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3666 - accuracy: 0.8785 - val_loss: 0.7113 - val_accuracy: 0.7912\n",
            "Epoch 129/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3697 - accuracy: 0.8792 - val_loss: 0.4629 - val_accuracy: 0.8534\n",
            "Epoch 130/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3662 - accuracy: 0.8803 - val_loss: 0.5332 - val_accuracy: 0.8357\n",
            "Epoch 131/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3691 - accuracy: 0.8759 - val_loss: 0.5701 - val_accuracy: 0.8258\n",
            "Epoch 132/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3685 - accuracy: 0.8780 - val_loss: 0.5062 - val_accuracy: 0.8458\n",
            "Epoch 133/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3666 - accuracy: 0.8790 - val_loss: 0.4665 - val_accuracy: 0.8556\n",
            "Epoch 134/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3659 - accuracy: 0.8777 - val_loss: 0.4759 - val_accuracy: 0.8519\n",
            "Epoch 135/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3577 - accuracy: 0.8817 - val_loss: 0.5339 - val_accuracy: 0.8396\n",
            "Epoch 136/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3566 - accuracy: 0.8830 - val_loss: 0.4816 - val_accuracy: 0.8484\n",
            "Epoch 137/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3593 - accuracy: 0.8817 - val_loss: 0.4952 - val_accuracy: 0.8462\n",
            "Epoch 138/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3548 - accuracy: 0.8840 - val_loss: 0.4632 - val_accuracy: 0.8509\n",
            "Epoch 139/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3533 - accuracy: 0.8833 - val_loss: 0.4450 - val_accuracy: 0.8570\n",
            "Epoch 140/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3582 - accuracy: 0.8826 - val_loss: 0.4696 - val_accuracy: 0.8499\n",
            "Epoch 141/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3483 - accuracy: 0.8849 - val_loss: 0.4506 - val_accuracy: 0.8591\n",
            "Epoch 142/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3495 - accuracy: 0.8844 - val_loss: 0.4511 - val_accuracy: 0.8560\n",
            "Epoch 143/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3439 - accuracy: 0.8870 - val_loss: 0.4760 - val_accuracy: 0.8505\n",
            "Epoch 144/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3476 - accuracy: 0.8844 - val_loss: 0.4716 - val_accuracy: 0.8552\n",
            "Epoch 145/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3426 - accuracy: 0.8866 - val_loss: 0.4541 - val_accuracy: 0.8637\n",
            "Epoch 146/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3369 - accuracy: 0.8880 - val_loss: 0.4662 - val_accuracy: 0.8558\n",
            "Epoch 147/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3423 - accuracy: 0.8882 - val_loss: 0.6844 - val_accuracy: 0.8078\n",
            "Epoch 148/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3410 - accuracy: 0.8878 - val_loss: 0.4377 - val_accuracy: 0.8623\n",
            "Epoch 149/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3418 - accuracy: 0.8857 - val_loss: 0.5039 - val_accuracy: 0.8468\n",
            "Epoch 150/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3345 - accuracy: 0.8881 - val_loss: 0.5082 - val_accuracy: 0.8459\n",
            "Epoch 151/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3305 - accuracy: 0.8903 - val_loss: 0.4552 - val_accuracy: 0.8551\n",
            "Epoch 152/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3327 - accuracy: 0.8899 - val_loss: 0.4595 - val_accuracy: 0.8575\n",
            "Epoch 153/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3330 - accuracy: 0.8895 - val_loss: 0.4352 - val_accuracy: 0.8660\n",
            "Epoch 154/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3302 - accuracy: 0.8915 - val_loss: 0.4359 - val_accuracy: 0.8617\n",
            "Epoch 155/200\n",
            "500/500 [==============================] - 37s 75ms/step - loss: 0.3294 - accuracy: 0.8916 - val_loss: 0.4429 - val_accuracy: 0.8598\n",
            "Epoch 156/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.3215 - accuracy: 0.8943 - val_loss: 0.5003 - val_accuracy: 0.8459\n",
            "Epoch 157/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3270 - accuracy: 0.8930 - val_loss: 0.4350 - val_accuracy: 0.8651\n",
            "Epoch 158/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3269 - accuracy: 0.8917 - val_loss: 0.4603 - val_accuracy: 0.8595\n",
            "Epoch 159/200\n",
            "500/500 [==============================] - 40s 79ms/step - loss: 0.3275 - accuracy: 0.8913 - val_loss: 0.4208 - val_accuracy: 0.8657\n",
            "Epoch 160/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3153 - accuracy: 0.8954 - val_loss: 0.5514 - val_accuracy: 0.8356\n",
            "Epoch 161/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3168 - accuracy: 0.8969 - val_loss: 0.5143 - val_accuracy: 0.8452\n",
            "Epoch 162/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3172 - accuracy: 0.8945 - val_loss: 0.4315 - val_accuracy: 0.8708\n",
            "Epoch 163/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3149 - accuracy: 0.8965 - val_loss: 0.4344 - val_accuracy: 0.8635\n",
            "Epoch 164/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3107 - accuracy: 0.8969 - val_loss: 0.4292 - val_accuracy: 0.8600\n",
            "Epoch 165/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.3205 - accuracy: 0.8941 - val_loss: 0.4779 - val_accuracy: 0.8485\n",
            "Epoch 166/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3150 - accuracy: 0.8970 - val_loss: 0.4988 - val_accuracy: 0.8456\n",
            "Epoch 167/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3178 - accuracy: 0.8952 - val_loss: 0.4710 - val_accuracy: 0.8534\n",
            "Epoch 168/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3137 - accuracy: 0.8962 - val_loss: 0.4742 - val_accuracy: 0.8575\n",
            "Epoch 169/200\n",
            "500/500 [==============================] - 39s 79ms/step - loss: 0.3116 - accuracy: 0.8972 - val_loss: 0.4285 - val_accuracy: 0.8646\n",
            "Epoch 170/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3063 - accuracy: 0.8984 - val_loss: 0.5897 - val_accuracy: 0.8264\n",
            "Epoch 171/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3078 - accuracy: 0.8978 - val_loss: 0.4186 - val_accuracy: 0.8714\n",
            "Epoch 172/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3058 - accuracy: 0.8991 - val_loss: 0.4183 - val_accuracy: 0.8672\n",
            "Epoch 173/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3026 - accuracy: 0.9000 - val_loss: 0.4300 - val_accuracy: 0.8683\n",
            "Epoch 174/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3023 - accuracy: 0.8989 - val_loss: 0.4893 - val_accuracy: 0.8497\n",
            "Epoch 175/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3044 - accuracy: 0.8990 - val_loss: 0.4447 - val_accuracy: 0.8647\n",
            "Epoch 176/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3017 - accuracy: 0.9000 - val_loss: 0.4657 - val_accuracy: 0.8558\n",
            "Epoch 177/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.2990 - accuracy: 0.8995 - val_loss: 0.4065 - val_accuracy: 0.8715\n",
            "Epoch 178/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3008 - accuracy: 0.9008 - val_loss: 0.5558 - val_accuracy: 0.8358\n",
            "Epoch 179/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3037 - accuracy: 0.8989 - val_loss: 0.5803 - val_accuracy: 0.8266\n",
            "Epoch 180/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3011 - accuracy: 0.9002 - val_loss: 0.4404 - val_accuracy: 0.8669\n",
            "Epoch 181/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2999 - accuracy: 0.8999 - val_loss: 0.4676 - val_accuracy: 0.8583\n",
            "Epoch 182/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2979 - accuracy: 0.9014 - val_loss: 0.4950 - val_accuracy: 0.8477\n",
            "Epoch 183/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.2990 - accuracy: 0.9009 - val_loss: 0.5549 - val_accuracy: 0.8392\n",
            "Epoch 184/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2875 - accuracy: 0.9042 - val_loss: 0.4517 - val_accuracy: 0.8619\n",
            "Epoch 185/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.2949 - accuracy: 0.9018 - val_loss: 0.4333 - val_accuracy: 0.8715\n",
            "Epoch 186/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2969 - accuracy: 0.9020 - val_loss: 0.4615 - val_accuracy: 0.8523\n",
            "Epoch 187/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.2907 - accuracy: 0.9016 - val_loss: 0.4483 - val_accuracy: 0.8614\n",
            "Epoch 188/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2894 - accuracy: 0.9047 - val_loss: 0.4558 - val_accuracy: 0.8622\n",
            "Epoch 189/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.2896 - accuracy: 0.9037 - val_loss: 0.4207 - val_accuracy: 0.8683\n",
            "Epoch 190/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.2880 - accuracy: 0.9047 - val_loss: 0.4324 - val_accuracy: 0.8685\n",
            "Epoch 191/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.2856 - accuracy: 0.9037 - val_loss: 0.4361 - val_accuracy: 0.8666\n",
            "Epoch 192/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.2886 - accuracy: 0.9042 - val_loss: 0.4184 - val_accuracy: 0.8741\n",
            "Epoch 193/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.2883 - accuracy: 0.9037 - val_loss: 0.4225 - val_accuracy: 0.8702\n",
            "Epoch 194/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.2841 - accuracy: 0.9073 - val_loss: 0.4656 - val_accuracy: 0.8584\n",
            "Epoch 195/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.2831 - accuracy: 0.9064 - val_loss: 0.4442 - val_accuracy: 0.8639\n",
            "Epoch 196/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.2791 - accuracy: 0.9067 - val_loss: 0.4409 - val_accuracy: 0.8616\n",
            "Epoch 197/200\n",
            "500/500 [==============================] - 38s 77ms/step - loss: 0.2830 - accuracy: 0.9065 - val_loss: 0.3892 - val_accuracy: 0.8782\n",
            "Epoch 198/200\n",
            "500/500 [==============================] - 38s 75ms/step - loss: 0.2805 - accuracy: 0.9069 - val_loss: 0.4772 - val_accuracy: 0.8569\n",
            "Epoch 199/200\n",
            "500/500 [==============================] - 38s 76ms/step - loss: 0.2781 - accuracy: 0.9084 - val_loss: 0.4048 - val_accuracy: 0.8756\n",
            "Epoch 200/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.2796 - accuracy: 0.9076 - val_loss: 0.4520 - val_accuracy: 0.8687\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.4520 - accuracy: 0.8687\n",
            "Test loss: 0.4520096778869629\n",
            "Test accuracy: 0.8687000274658203\n"
          ]
        }
      ]
    }
  ]
}
