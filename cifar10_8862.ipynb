{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM9jZFil++V4nnDLbuKTOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igrodfer/DeepLearningLab/blob/main/cifar10_8862.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h5wdHR13H09N"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Add\n",
        "from keras.layers import BatchNormalization as BN\n",
        "from keras.layers import GaussianNoise as GN\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras import Input, Model\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "GpI8v1zTuKyl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBkZNs-FuNRX",
        "outputId": "ea559a5e-6fbb-44b5-f784-af196ed23a55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2)"
      ],
      "metadata": {
        "id": "DDLd-1f1uTVl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resblock(x, filters,ds=False):\n",
        "  fx = Conv2D(filters, (3,3), strides=(1 if not ds else 2), padding='same')(x)\n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  fx = Activation('relu')(fx)\n",
        "\n",
        "  fx = Conv2D(filters, (3,3), padding='same')(fx)\n",
        "\n",
        "  if ds:\n",
        "    x = Conv2D(filters, (1,1),strides=2, padding='same')(x)\n",
        "\n",
        "  out = Add()([x,fx])\n",
        "\n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  out = Activation('relu')(fx)\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "48aEBFEPIHkI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CBGN(x,filters,ishape=0):\n",
        "  if (ishape!=0):\n",
        "    fx = Conv2D(filters, (3, 3), padding='same',\n",
        "                 input_shape=ishape)(x)\n",
        "  else:\n",
        "    fx = Conv2D(filters, (3, 3), padding='same')(x)\n",
        "  \n",
        "  fx = BN()(fx)\n",
        "  fx = GN(0.3)(fx)\n",
        "  fx = Activation('relu')(fx)\n",
        "  fx = MaxPooling2D(pool_size=(2, 2))(fx)\n",
        "  \n",
        "  return fx"
      ],
      "metadata": {
        "id": "Fqwy-6K1Jbkq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=x_train.shape[1:])\n",
        "\n",
        "out = CBGN(input,32)\n",
        "out = resblock(out,32)\n",
        "out = resblock(out,32)\n",
        "\n",
        "out = resblock(out,64,True)\n",
        "out = resblock(out,64)\n",
        "out = resblock(out,64)\n",
        "\n",
        "out = resblock(out,128,True)\n",
        "out = resblock(out,128)\n",
        "out = resblock(out,128)\n",
        "\n",
        "out = resblock(out,256,True)\n",
        "out = resblock(out,256)\n",
        "#out = resblock(out,256)\n",
        "\n",
        "#out = resblock(out,512,True)\n",
        "#out = resblock(out,512)\n",
        "\n",
        "out = Flatten()(out)\n",
        "out = Dense(512)(out)\n",
        "out = BN()(out)\n",
        "out = GN(0.3)(out)\n",
        "out = Activation('relu')(out)\n",
        "\n",
        "out = Flatten()(out)\n",
        "out = Dense(num_classes)(out)\n",
        "out = Activation('softmax')(out)\n",
        "\n",
        "model = Model(input,out)"
      ],
      "metadata": {
        "id": "5IbFeCXrKoeY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-xJ3cOuFvCMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## OPTIM AND COMPILE\n",
        "opt = SGD(learning_rate=0.01, decay=1e-6,momentum=0.9)\n",
        "opt = Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "g4ZCddjbvMZ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(x_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            verbose=1)\n",
        "\n",
        "## TEST\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ99AM-1vOdz",
        "outputId": "b59224e9-1343-4b88-db4d-74d752994840"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "500/500 [==============================] - 47s 75ms/step - loss: 1.9679 - accuracy: 0.2470 - val_loss: 2.9331 - val_accuracy: 0.2580\n",
            "Epoch 2/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 1.6906 - accuracy: 0.3659 - val_loss: 2.0461 - val_accuracy: 0.3652\n",
            "Epoch 3/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.5365 - accuracy: 0.4362 - val_loss: 2.1171 - val_accuracy: 0.4349\n",
            "Epoch 4/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 1.4247 - accuracy: 0.4820 - val_loss: 2.8961 - val_accuracy: 0.4255\n",
            "Epoch 5/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.3405 - accuracy: 0.5185 - val_loss: 2.5397 - val_accuracy: 0.4310\n",
            "Epoch 6/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 1.2784 - accuracy: 0.5451 - val_loss: 2.8737 - val_accuracy: 0.3865\n",
            "Epoch 7/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 1.2163 - accuracy: 0.5689 - val_loss: 3.1327 - val_accuracy: 0.3878\n",
            "Epoch 8/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 1.1761 - accuracy: 0.5839 - val_loss: 1.4462 - val_accuracy: 0.5779\n",
            "Epoch 9/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 1.1249 - accuracy: 0.6042 - val_loss: 1.3026 - val_accuracy: 0.6055\n",
            "Epoch 10/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 1.0874 - accuracy: 0.6174 - val_loss: 1.6493 - val_accuracy: 0.5560\n",
            "Epoch 11/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 1.0547 - accuracy: 0.6332 - val_loss: 1.1350 - val_accuracy: 0.6479\n",
            "Epoch 12/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 1.0280 - accuracy: 0.6433 - val_loss: 1.0707 - val_accuracy: 0.6732\n",
            "Epoch 13/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 1.0014 - accuracy: 0.6543 - val_loss: 1.0872 - val_accuracy: 0.6701\n",
            "Epoch 14/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.9699 - accuracy: 0.6674 - val_loss: 1.0282 - val_accuracy: 0.6576\n",
            "Epoch 15/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.9447 - accuracy: 0.6765 - val_loss: 2.0637 - val_accuracy: 0.5027\n",
            "Epoch 16/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.9162 - accuracy: 0.6856 - val_loss: 1.1940 - val_accuracy: 0.6750\n",
            "Epoch 17/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.9058 - accuracy: 0.6912 - val_loss: 1.0892 - val_accuracy: 0.6780\n",
            "Epoch 18/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.8875 - accuracy: 0.6977 - val_loss: 1.2503 - val_accuracy: 0.6295\n",
            "Epoch 19/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.8681 - accuracy: 0.7067 - val_loss: 1.2823 - val_accuracy: 0.6538\n",
            "Epoch 20/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.8469 - accuracy: 0.7134 - val_loss: 0.8614 - val_accuracy: 0.7306\n",
            "Epoch 21/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.8304 - accuracy: 0.7185 - val_loss: 1.0315 - val_accuracy: 0.6892\n",
            "Epoch 22/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.8215 - accuracy: 0.7245 - val_loss: 0.8495 - val_accuracy: 0.7308\n",
            "Epoch 23/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.8039 - accuracy: 0.7306 - val_loss: 0.9392 - val_accuracy: 0.6997\n",
            "Epoch 24/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.7921 - accuracy: 0.7324 - val_loss: 0.7192 - val_accuracy: 0.7676\n",
            "Epoch 25/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.7776 - accuracy: 0.7411 - val_loss: 0.7893 - val_accuracy: 0.7462\n",
            "Epoch 26/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.7713 - accuracy: 0.7418 - val_loss: 0.7716 - val_accuracy: 0.7554\n",
            "Epoch 27/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.7559 - accuracy: 0.7467 - val_loss: 0.9530 - val_accuracy: 0.7269\n",
            "Epoch 28/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.7360 - accuracy: 0.7528 - val_loss: 0.7771 - val_accuracy: 0.7671\n",
            "Epoch 29/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.7310 - accuracy: 0.7569 - val_loss: 0.8997 - val_accuracy: 0.7420\n",
            "Epoch 30/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.7156 - accuracy: 0.7627 - val_loss: 0.7473 - val_accuracy: 0.7665\n",
            "Epoch 31/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.7095 - accuracy: 0.7639 - val_loss: 0.7358 - val_accuracy: 0.7594\n",
            "Epoch 32/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.7069 - accuracy: 0.7670 - val_loss: 0.8415 - val_accuracy: 0.7324\n",
            "Epoch 33/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.7002 - accuracy: 0.7672 - val_loss: 0.7539 - val_accuracy: 0.7645\n",
            "Epoch 34/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.6791 - accuracy: 0.7740 - val_loss: 0.7344 - val_accuracy: 0.7707\n",
            "Epoch 35/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.6793 - accuracy: 0.7739 - val_loss: 0.7646 - val_accuracy: 0.7682\n",
            "Epoch 36/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.6652 - accuracy: 0.7784 - val_loss: 0.6854 - val_accuracy: 0.7798\n",
            "Epoch 37/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.6617 - accuracy: 0.7793 - val_loss: 0.7977 - val_accuracy: 0.7579\n",
            "Epoch 38/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.6519 - accuracy: 0.7810 - val_loss: 0.6197 - val_accuracy: 0.8016\n",
            "Epoch 39/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.6420 - accuracy: 0.7870 - val_loss: 0.6728 - val_accuracy: 0.7762\n",
            "Epoch 40/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.6379 - accuracy: 0.7874 - val_loss: 0.7189 - val_accuracy: 0.7796\n",
            "Epoch 41/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.6371 - accuracy: 0.7875 - val_loss: 0.5960 - val_accuracy: 0.8036\n",
            "Epoch 42/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.6181 - accuracy: 0.7940 - val_loss: 0.5660 - val_accuracy: 0.8222\n",
            "Epoch 43/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.6206 - accuracy: 0.7942 - val_loss: 0.7219 - val_accuracy: 0.7849\n",
            "Epoch 44/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.6074 - accuracy: 0.7981 - val_loss: 0.7118 - val_accuracy: 0.7822\n",
            "Epoch 45/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.6046 - accuracy: 0.7987 - val_loss: 0.6268 - val_accuracy: 0.8007\n",
            "Epoch 46/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5984 - accuracy: 0.7985 - val_loss: 0.7333 - val_accuracy: 0.7669\n",
            "Epoch 47/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5984 - accuracy: 0.7992 - val_loss: 0.6633 - val_accuracy: 0.7919\n",
            "Epoch 48/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5809 - accuracy: 0.8056 - val_loss: 0.5944 - val_accuracy: 0.8122\n",
            "Epoch 49/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5833 - accuracy: 0.8064 - val_loss: 0.7050 - val_accuracy: 0.7903\n",
            "Epoch 50/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.5764 - accuracy: 0.8074 - val_loss: 0.5607 - val_accuracy: 0.8144\n",
            "Epoch 51/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5679 - accuracy: 0.8104 - val_loss: 0.8581 - val_accuracy: 0.7477\n",
            "Epoch 52/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5624 - accuracy: 0.8104 - val_loss: 0.5996 - val_accuracy: 0.8110\n",
            "Epoch 53/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5638 - accuracy: 0.8094 - val_loss: 0.5877 - val_accuracy: 0.8144\n",
            "Epoch 54/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.5563 - accuracy: 0.8130 - val_loss: 0.5077 - val_accuracy: 0.8328\n",
            "Epoch 55/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5509 - accuracy: 0.8162 - val_loss: 0.5714 - val_accuracy: 0.8181\n",
            "Epoch 56/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5454 - accuracy: 0.8163 - val_loss: 0.7998 - val_accuracy: 0.7660\n",
            "Epoch 57/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.5393 - accuracy: 0.8203 - val_loss: 0.5818 - val_accuracy: 0.8169\n",
            "Epoch 58/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5385 - accuracy: 0.8202 - val_loss: 0.7801 - val_accuracy: 0.7693\n",
            "Epoch 59/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.5323 - accuracy: 0.8219 - val_loss: 0.5720 - val_accuracy: 0.8193\n",
            "Epoch 60/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.5311 - accuracy: 0.8226 - val_loss: 0.4569 - val_accuracy: 0.8480\n",
            "Epoch 61/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.5282 - accuracy: 0.8227 - val_loss: 0.5827 - val_accuracy: 0.8200\n",
            "Epoch 62/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.5292 - accuracy: 0.8237 - val_loss: 0.5797 - val_accuracy: 0.8115\n",
            "Epoch 63/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.5168 - accuracy: 0.8254 - val_loss: 0.7708 - val_accuracy: 0.7708\n",
            "Epoch 64/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.5124 - accuracy: 0.8279 - val_loss: 0.5930 - val_accuracy: 0.8205\n",
            "Epoch 65/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.5069 - accuracy: 0.8309 - val_loss: 0.5096 - val_accuracy: 0.8390\n",
            "Epoch 66/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5075 - accuracy: 0.8286 - val_loss: 0.5233 - val_accuracy: 0.8359\n",
            "Epoch 67/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.5062 - accuracy: 0.8292 - val_loss: 0.4605 - val_accuracy: 0.8531\n",
            "Epoch 68/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4965 - accuracy: 0.8328 - val_loss: 0.6768 - val_accuracy: 0.7989\n",
            "Epoch 69/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4943 - accuracy: 0.8331 - val_loss: 0.6603 - val_accuracy: 0.8040\n",
            "Epoch 70/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4919 - accuracy: 0.8331 - val_loss: 0.5050 - val_accuracy: 0.8394\n",
            "Epoch 71/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4886 - accuracy: 0.8360 - val_loss: 0.5573 - val_accuracy: 0.8182\n",
            "Epoch 72/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4886 - accuracy: 0.8359 - val_loss: 0.4597 - val_accuracy: 0.8483\n",
            "Epoch 73/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4827 - accuracy: 0.8389 - val_loss: 0.5098 - val_accuracy: 0.8346\n",
            "Epoch 74/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4813 - accuracy: 0.8376 - val_loss: 0.4603 - val_accuracy: 0.8469\n",
            "Epoch 75/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.4828 - accuracy: 0.8384 - val_loss: 0.4627 - val_accuracy: 0.8467\n",
            "Epoch 76/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4808 - accuracy: 0.8395 - val_loss: 0.5296 - val_accuracy: 0.8286\n",
            "Epoch 77/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4775 - accuracy: 0.8394 - val_loss: 0.4763 - val_accuracy: 0.8461\n",
            "Epoch 78/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4756 - accuracy: 0.8400 - val_loss: 0.4474 - val_accuracy: 0.8495\n",
            "Epoch 79/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.4702 - accuracy: 0.8408 - val_loss: 0.6303 - val_accuracy: 0.8126\n",
            "Epoch 80/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4655 - accuracy: 0.8433 - val_loss: 0.7139 - val_accuracy: 0.7938\n",
            "Epoch 81/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4650 - accuracy: 0.8430 - val_loss: 0.5691 - val_accuracy: 0.8225\n",
            "Epoch 82/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4633 - accuracy: 0.8443 - val_loss: 0.5784 - val_accuracy: 0.8204\n",
            "Epoch 83/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.4650 - accuracy: 0.8442 - val_loss: 0.4727 - val_accuracy: 0.8416\n",
            "Epoch 84/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4565 - accuracy: 0.8466 - val_loss: 0.4385 - val_accuracy: 0.8529\n",
            "Epoch 85/200\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 0.4554 - accuracy: 0.8476 - val_loss: 0.4848 - val_accuracy: 0.8416\n",
            "Epoch 86/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4541 - accuracy: 0.8473 - val_loss: 0.4511 - val_accuracy: 0.8583\n",
            "Epoch 87/200\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 0.4577 - accuracy: 0.8465 - val_loss: 0.4658 - val_accuracy: 0.8506\n",
            "Epoch 88/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4464 - accuracy: 0.8487 - val_loss: 0.5062 - val_accuracy: 0.8378\n",
            "Epoch 89/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4459 - accuracy: 0.8508 - val_loss: 0.4267 - val_accuracy: 0.8590\n",
            "Epoch 90/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4448 - accuracy: 0.8508 - val_loss: 0.5995 - val_accuracy: 0.8235\n",
            "Epoch 91/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4404 - accuracy: 0.8527 - val_loss: 0.4623 - val_accuracy: 0.8468\n",
            "Epoch 92/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4432 - accuracy: 0.8518 - val_loss: 0.5368 - val_accuracy: 0.8337\n",
            "Epoch 93/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4374 - accuracy: 0.8533 - val_loss: 0.5081 - val_accuracy: 0.8435\n",
            "Epoch 94/200\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.4385 - accuracy: 0.8522 - val_loss: 0.4680 - val_accuracy: 0.8533\n",
            "Epoch 95/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4313 - accuracy: 0.8546 - val_loss: 0.4773 - val_accuracy: 0.8478\n",
            "Epoch 96/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4332 - accuracy: 0.8549 - val_loss: 0.4941 - val_accuracy: 0.8390\n",
            "Epoch 97/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4247 - accuracy: 0.8565 - val_loss: 0.4570 - val_accuracy: 0.8550\n",
            "Epoch 98/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.4265 - accuracy: 0.8555 - val_loss: 0.4359 - val_accuracy: 0.8577\n",
            "Epoch 99/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4236 - accuracy: 0.8570 - val_loss: 0.4529 - val_accuracy: 0.8552\n",
            "Epoch 100/200\n",
            "500/500 [==============================] - 34s 67ms/step - loss: 0.4224 - accuracy: 0.8587 - val_loss: 0.4153 - val_accuracy: 0.8624\n",
            "Epoch 101/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4249 - accuracy: 0.8575 - val_loss: 0.4473 - val_accuracy: 0.8562\n",
            "Epoch 102/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4162 - accuracy: 0.8601 - val_loss: 0.5686 - val_accuracy: 0.8258\n",
            "Epoch 103/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4145 - accuracy: 0.8599 - val_loss: 0.5423 - val_accuracy: 0.8343\n",
            "Epoch 104/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4194 - accuracy: 0.8593 - val_loss: 0.4804 - val_accuracy: 0.8469\n",
            "Epoch 105/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.4127 - accuracy: 0.8610 - val_loss: 0.4510 - val_accuracy: 0.8522\n",
            "Epoch 106/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4117 - accuracy: 0.8608 - val_loss: 0.5217 - val_accuracy: 0.8440\n",
            "Epoch 107/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4100 - accuracy: 0.8615 - val_loss: 0.4457 - val_accuracy: 0.8589\n",
            "Epoch 108/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4116 - accuracy: 0.8608 - val_loss: 0.4136 - val_accuracy: 0.8658\n",
            "Epoch 109/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.4113 - accuracy: 0.8630 - val_loss: 0.5301 - val_accuracy: 0.8401\n",
            "Epoch 110/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.4081 - accuracy: 0.8630 - val_loss: 0.4593 - val_accuracy: 0.8528\n",
            "Epoch 111/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.4013 - accuracy: 0.8632 - val_loss: 0.4401 - val_accuracy: 0.8597\n",
            "Epoch 112/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.4050 - accuracy: 0.8645 - val_loss: 0.5210 - val_accuracy: 0.8376\n",
            "Epoch 113/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3980 - accuracy: 0.8665 - val_loss: 0.4603 - val_accuracy: 0.8555\n",
            "Epoch 114/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.3984 - accuracy: 0.8659 - val_loss: 0.3788 - val_accuracy: 0.8752\n",
            "Epoch 115/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3950 - accuracy: 0.8660 - val_loss: 0.4289 - val_accuracy: 0.8569\n",
            "Epoch 116/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3986 - accuracy: 0.8662 - val_loss: 0.4414 - val_accuracy: 0.8613\n",
            "Epoch 117/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3945 - accuracy: 0.8679 - val_loss: 0.4192 - val_accuracy: 0.8667\n",
            "Epoch 118/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3920 - accuracy: 0.8692 - val_loss: 0.3868 - val_accuracy: 0.8729\n",
            "Epoch 119/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3881 - accuracy: 0.8699 - val_loss: 0.4337 - val_accuracy: 0.8597\n",
            "Epoch 120/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.3921 - accuracy: 0.8670 - val_loss: 0.4216 - val_accuracy: 0.8622\n",
            "Epoch 121/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3854 - accuracy: 0.8709 - val_loss: 0.4182 - val_accuracy: 0.8694\n",
            "Epoch 122/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3904 - accuracy: 0.8674 - val_loss: 0.3903 - val_accuracy: 0.8696\n",
            "Epoch 123/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3809 - accuracy: 0.8712 - val_loss: 0.4334 - val_accuracy: 0.8621\n",
            "Epoch 124/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3807 - accuracy: 0.8728 - val_loss: 0.4022 - val_accuracy: 0.8721\n",
            "Epoch 125/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.3861 - accuracy: 0.8696 - val_loss: 0.5106 - val_accuracy: 0.8359\n",
            "Epoch 126/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3827 - accuracy: 0.8715 - val_loss: 0.4415 - val_accuracy: 0.8628\n",
            "Epoch 127/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3750 - accuracy: 0.8728 - val_loss: 0.3632 - val_accuracy: 0.8790\n",
            "Epoch 128/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3790 - accuracy: 0.8728 - val_loss: 0.4142 - val_accuracy: 0.8671\n",
            "Epoch 129/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3780 - accuracy: 0.8724 - val_loss: 0.4284 - val_accuracy: 0.8635\n",
            "Epoch 130/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3747 - accuracy: 0.8735 - val_loss: 0.4828 - val_accuracy: 0.8479\n",
            "Epoch 131/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3749 - accuracy: 0.8742 - val_loss: 0.3884 - val_accuracy: 0.8711\n",
            "Epoch 132/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3735 - accuracy: 0.8748 - val_loss: 0.4189 - val_accuracy: 0.8679\n",
            "Epoch 133/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.3710 - accuracy: 0.8741 - val_loss: 0.4460 - val_accuracy: 0.8618\n",
            "Epoch 134/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.3723 - accuracy: 0.8740 - val_loss: 0.4012 - val_accuracy: 0.8691\n",
            "Epoch 135/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3681 - accuracy: 0.8745 - val_loss: 0.4195 - val_accuracy: 0.8672\n",
            "Epoch 136/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3685 - accuracy: 0.8747 - val_loss: 0.4132 - val_accuracy: 0.8680\n",
            "Epoch 137/200\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.3587 - accuracy: 0.8782 - val_loss: 0.3948 - val_accuracy: 0.8729\n",
            "Epoch 138/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3681 - accuracy: 0.8748 - val_loss: 0.3794 - val_accuracy: 0.8772\n",
            "Epoch 139/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3631 - accuracy: 0.8774 - val_loss: 0.3919 - val_accuracy: 0.8750\n",
            "Epoch 140/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3619 - accuracy: 0.8779 - val_loss: 0.3802 - val_accuracy: 0.8762\n",
            "Epoch 141/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3623 - accuracy: 0.8767 - val_loss: 0.3946 - val_accuracy: 0.8711\n",
            "Epoch 142/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3515 - accuracy: 0.8826 - val_loss: 0.5101 - val_accuracy: 0.8485\n",
            "Epoch 143/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3609 - accuracy: 0.8786 - val_loss: 0.4552 - val_accuracy: 0.8574\n",
            "Epoch 144/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3574 - accuracy: 0.8791 - val_loss: 0.3863 - val_accuracy: 0.8760\n",
            "Epoch 145/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3565 - accuracy: 0.8786 - val_loss: 0.4064 - val_accuracy: 0.8705\n",
            "Epoch 146/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3588 - accuracy: 0.8789 - val_loss: 0.4323 - val_accuracy: 0.8620\n",
            "Epoch 147/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3557 - accuracy: 0.8799 - val_loss: 0.4010 - val_accuracy: 0.8713\n",
            "Epoch 148/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3520 - accuracy: 0.8800 - val_loss: 0.4340 - val_accuracy: 0.8634\n",
            "Epoch 149/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3558 - accuracy: 0.8800 - val_loss: 0.5258 - val_accuracy: 0.8376\n",
            "Epoch 150/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3537 - accuracy: 0.8797 - val_loss: 0.4242 - val_accuracy: 0.8640\n",
            "Epoch 151/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3470 - accuracy: 0.8816 - val_loss: 0.4801 - val_accuracy: 0.8491\n",
            "Epoch 152/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3487 - accuracy: 0.8824 - val_loss: 0.4523 - val_accuracy: 0.8545\n",
            "Epoch 153/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3511 - accuracy: 0.8797 - val_loss: 0.3590 - val_accuracy: 0.8847\n",
            "Epoch 154/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3442 - accuracy: 0.8839 - val_loss: 0.4029 - val_accuracy: 0.8759\n",
            "Epoch 155/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3475 - accuracy: 0.8828 - val_loss: 0.4043 - val_accuracy: 0.8721\n",
            "Epoch 156/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3419 - accuracy: 0.8831 - val_loss: 0.3763 - val_accuracy: 0.8800\n",
            "Epoch 157/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3409 - accuracy: 0.8861 - val_loss: 0.4280 - val_accuracy: 0.8679\n",
            "Epoch 158/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3415 - accuracy: 0.8843 - val_loss: 0.4562 - val_accuracy: 0.8619\n",
            "Epoch 159/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3442 - accuracy: 0.8834 - val_loss: 0.3657 - val_accuracy: 0.8832\n",
            "Epoch 160/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3416 - accuracy: 0.8846 - val_loss: 0.4279 - val_accuracy: 0.8642\n",
            "Epoch 161/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3389 - accuracy: 0.8848 - val_loss: 0.3745 - val_accuracy: 0.8801\n",
            "Epoch 162/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3383 - accuracy: 0.8846 - val_loss: 0.3802 - val_accuracy: 0.8712\n",
            "Epoch 163/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3354 - accuracy: 0.8862 - val_loss: 0.3911 - val_accuracy: 0.8740\n",
            "Epoch 164/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3376 - accuracy: 0.8861 - val_loss: 0.4519 - val_accuracy: 0.8592\n",
            "Epoch 165/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3373 - accuracy: 0.8851 - val_loss: 0.3623 - val_accuracy: 0.8836\n",
            "Epoch 166/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3336 - accuracy: 0.8854 - val_loss: 0.3924 - val_accuracy: 0.8725\n",
            "Epoch 167/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3318 - accuracy: 0.8879 - val_loss: 0.4007 - val_accuracy: 0.8740\n",
            "Epoch 168/200\n",
            "500/500 [==============================] - 36s 71ms/step - loss: 0.3299 - accuracy: 0.8869 - val_loss: 0.4878 - val_accuracy: 0.8500\n",
            "Epoch 169/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3341 - accuracy: 0.8855 - val_loss: 0.3626 - val_accuracy: 0.8822\n",
            "Epoch 170/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3279 - accuracy: 0.8885 - val_loss: 0.4319 - val_accuracy: 0.8616\n",
            "Epoch 171/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3320 - accuracy: 0.8857 - val_loss: 0.4139 - val_accuracy: 0.8699\n",
            "Epoch 172/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3288 - accuracy: 0.8879 - val_loss: 0.3795 - val_accuracy: 0.8773\n",
            "Epoch 173/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3257 - accuracy: 0.8899 - val_loss: 0.4612 - val_accuracy: 0.8654\n",
            "Epoch 174/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3274 - accuracy: 0.8879 - val_loss: 0.3503 - val_accuracy: 0.8878\n",
            "Epoch 175/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3240 - accuracy: 0.8894 - val_loss: 0.4452 - val_accuracy: 0.8640\n",
            "Epoch 176/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3222 - accuracy: 0.8901 - val_loss: 0.4121 - val_accuracy: 0.8712\n",
            "Epoch 177/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3246 - accuracy: 0.8892 - val_loss: 0.4765 - val_accuracy: 0.8516\n",
            "Epoch 178/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3201 - accuracy: 0.8925 - val_loss: 0.3567 - val_accuracy: 0.8833\n",
            "Epoch 179/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3227 - accuracy: 0.8897 - val_loss: 0.3960 - val_accuracy: 0.8766\n",
            "Epoch 180/200\n",
            "500/500 [==============================] - 37s 75ms/step - loss: 0.3188 - accuracy: 0.8919 - val_loss: 0.4273 - val_accuracy: 0.8655\n",
            "Epoch 181/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3208 - accuracy: 0.8915 - val_loss: 0.4504 - val_accuracy: 0.8572\n",
            "Epoch 182/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3170 - accuracy: 0.8915 - val_loss: 0.4574 - val_accuracy: 0.8628\n",
            "Epoch 183/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3226 - accuracy: 0.8923 - val_loss: 0.4751 - val_accuracy: 0.8539\n",
            "Epoch 184/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3152 - accuracy: 0.8937 - val_loss: 0.4410 - val_accuracy: 0.8608\n",
            "Epoch 185/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3151 - accuracy: 0.8913 - val_loss: 0.5238 - val_accuracy: 0.8393\n",
            "Epoch 186/200\n",
            "500/500 [==============================] - 34s 69ms/step - loss: 0.3202 - accuracy: 0.8914 - val_loss: 0.3568 - val_accuracy: 0.8863\n",
            "Epoch 187/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3119 - accuracy: 0.8933 - val_loss: 0.4120 - val_accuracy: 0.8716\n",
            "Epoch 188/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3127 - accuracy: 0.8928 - val_loss: 0.3844 - val_accuracy: 0.8790\n",
            "Epoch 189/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3096 - accuracy: 0.8942 - val_loss: 0.3780 - val_accuracy: 0.8785\n",
            "Epoch 190/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3105 - accuracy: 0.8953 - val_loss: 0.3721 - val_accuracy: 0.8791\n",
            "Epoch 191/200\n",
            "500/500 [==============================] - 35s 71ms/step - loss: 0.3104 - accuracy: 0.8942 - val_loss: 0.4126 - val_accuracy: 0.8720\n",
            "Epoch 192/200\n",
            "500/500 [==============================] - 36s 73ms/step - loss: 0.3083 - accuracy: 0.8952 - val_loss: 0.4044 - val_accuracy: 0.8765\n",
            "Epoch 193/200\n",
            "500/500 [==============================] - 35s 70ms/step - loss: 0.3110 - accuracy: 0.8953 - val_loss: 0.4020 - val_accuracy: 0.8746\n",
            "Epoch 194/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3111 - accuracy: 0.8934 - val_loss: 0.3592 - val_accuracy: 0.8837\n",
            "Epoch 195/200\n",
            "500/500 [==============================] - 35s 69ms/step - loss: 0.3069 - accuracy: 0.8948 - val_loss: 0.3862 - val_accuracy: 0.8733\n",
            "Epoch 196/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3034 - accuracy: 0.8957 - val_loss: 0.4338 - val_accuracy: 0.8710\n",
            "Epoch 197/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3049 - accuracy: 0.8967 - val_loss: 0.4511 - val_accuracy: 0.8660\n",
            "Epoch 198/200\n",
            "500/500 [==============================] - 37s 73ms/step - loss: 0.3052 - accuracy: 0.8958 - val_loss: 0.3825 - val_accuracy: 0.8841\n",
            "Epoch 199/200\n",
            "500/500 [==============================] - 36s 72ms/step - loss: 0.3057 - accuracy: 0.8946 - val_loss: 0.3652 - val_accuracy: 0.8885\n",
            "Epoch 200/200\n",
            "500/500 [==============================] - 37s 74ms/step - loss: 0.3010 - accuracy: 0.8970 - val_loss: 0.3448 - val_accuracy: 0.8862\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3448 - accuracy: 0.8862\n",
            "Test loss: 0.34480729699134827\n",
            "Test accuracy: 0.8862000107765198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xslKKrdmrnOR",
        "outputId": "bd5e0273-ad9d-4478-eabd-2456c7189ff3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}